#!/usr/bin/python3

# Instruct the Kolibri content server to import Endless Key channels needed for
# this build.

import eib
import logging
from netrc import netrc
import os
import requests
from urllib.parse import urljoin, urlparse

logger = logging.getLogger(os.path.basename(__file__))


def get_job_status(session, base_url, job_id):
    url = urljoin(base_url, f'api/tasks/tasks/{job_id}/')
    with session.get(url) as resp:
        resp.raise_for_status()
        return resp.json()


def wait_for_job(session, base_url, job_id):
    logger.debug(f'Waiting for job {job_id} to complete')
    last_marker = None
    while True:
        data = get_job_status(session, base_url, job_id)

        # See the kolibri.core.tasks.job.State class for potential states
        # https://github.com/learningequality/kolibri/blob/develop/kolibri/core/tasks/job.py#L17
        status = data['status']
        if status == 'FAILED':
            logger.error(
              f'Job {job_id} failed: {data["exception"]}\n{data["traceback"]}'
            )
            raise Exception(f'Job {job_id} failed')
        elif status == 'CANCELED':
            raise Exception(f'Job {job_id} cancelled')
        elif status == 'COMPLETED':
            if last_marker < 100:
                logger.info('Progress: 100%')
            break

        pct = int(data['percentage'] * 100)
        marker = pct - pct % 5
        if last_marker is None or marker > last_marker:
            logger.info(f'Progress: {pct}%')
            last_marker = marker


def import_channel(session, base_url, channel_id):
    url = urljoin(base_url, 'api/tasks/tasks/startremotechannelimport/')
    data = {'channel_id': channel_id}
    logger.info(f'Importing channel {channel_id} metadata')
    with session.post(url, json=data) as resp:
        try:
            resp.raise_for_status()
        except requests.exceptions.HTTPError:
            logger.error('Failed to import channel: %s', resp.json())
            raise
        job = resp.json()
    wait_for_job(session, base_url, job['id'])


def import_content(session, base_url, channel_id):
    url = urljoin(base_url, 'api/tasks/tasks/startremotecontentimport/')
    data = {
        'channel_id': channel_id,
        'fail_on_error': True,
        'timeout': 300,
    }
    logger.info(f'Importing channel {channel_id} content')
    with session.post(url, json=data) as resp:
        try:
            resp.raise_for_status()
        except requests.exceptions.HTTPError:
            logger.error('Failed to import content: %s', resp.json())
            raise
        job = resp.json()
    wait_for_job(session, base_url, job['id'])


def main():
    eib.setup_logging()
    config = eib.get_config()

    base_url = config.get('kolibri', 'central_content_base_url', fallback=None)
    if not base_url:
        logger.info('Not using custom Kolibri content server')
        return

    netrc_path = os.path.join(eib.SYSCONFDIR, 'netrc')
    if not os.path.exists(netrc_path):
        logger.info(f'No credentials in {netrc_path}')
        return

    # This file gets populated by hooks/image/51-ek-content-list
    channels_path = os.path.join(os.environ['EIB_TMPDIR'], 'ek-channels')
    if not os.path.exists(channels_path):
        logger.info(f'No channel list in {channels_path}')
        return

    netrc_creds = netrc(netrc_path)
    host = urlparse(base_url).netloc
    creds = netrc_creds.authenticators(host)
    if not creds:
        logger.info(f'No credentials for {host}')
        return
    username, _, password = creds

    # Start a requests session with the credentials.
    session = requests.Session()
    session.auth = (username, password)
    session.headers.update({
        'Content-Type': 'application/json',
    })

    with open(channels_path) as channels_file:
        for line in channels_file:
            channel = line.strip()
            import_channel(session, base_url, channel)
            import_content(session, base_url, channel)


if __name__ == '__main__':
    main()
